# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2001-2018, Python Software Foundation
# This file is distributed under the same license as the Python package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2018.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Python 3.6\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-04-27 02:24-0700\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.5.3\n"

#: ../../reference/grammar.rst:2
msgid "Full Grammar specification"
msgstr ""

#: ../../reference/grammar.rst:4
msgid ""
"This is the full Python grammar, as it is read by the parser generator "
"and used to parse Python source files:"
msgstr ""

#: ../../reference/grammar.rst:7
msgid ""
"# Grammar for Python\n"
"\n"
"# NOTE WELL: You should also follow all the steps listed at\n"
"# https://devguide.python.org/grammar/\n"
"\n"
"# Start symbols for the grammar:\n"
"#       single_input is a single interactive statement;\n"
"#       file_input is a module or sequence of commands read from an input"
" file;\n"
"#       eval_input is the input for the eval() functions.\n"
"# NB: compound_stmt in single_input is followed by extra NEWLINE!\n"
"single_input: NEWLINE | simple_stmt | compound_stmt NEWLINE\n"
"file_input: (NEWLINE | stmt)* ENDMARKER\n"
"eval_input: testlist NEWLINE* ENDMARKER\n"
"\n"
"decorator: '@' dotted_name [ '(' [arglist] ')' ] NEWLINE\n"
"decorators: decorator+\n"
"decorated: decorators (classdef | funcdef | async_funcdef)\n"
"\n"
"async_funcdef: ASYNC funcdef\n"
"funcdef: 'def' NAME parameters ['->' test] ':' suite\n"
"\n"
"parameters: '(' [typedargslist] ')'\n"
"typedargslist: (tfpdef ['=' test] (',' tfpdef ['=' test])* [',' [\n"
"        '*' [tfpdef] (',' tfpdef ['=' test])* [',' ['**' tfpdef [',']]]\n"
"      | '**' tfpdef [',']]]\n"
"  | '*' [tfpdef] (',' tfpdef ['=' test])* [',' ['**' tfpdef [',']]]\n"
"  | '**' tfpdef [','])\n"
"tfpdef: NAME [':' test]\n"
"varargslist: (vfpdef ['=' test] (',' vfpdef ['=' test])* [',' [\n"
"        '*' [vfpdef] (',' vfpdef ['=' test])* [',' ['**' vfpdef [',']]]\n"
"      | '**' vfpdef [',']]]\n"
"  | '*' [vfpdef] (',' vfpdef ['=' test])* [',' ['**' vfpdef [',']]]\n"
"  | '**' vfpdef [',']\n"
")\n"
"vfpdef: NAME\n"
"\n"
"stmt: simple_stmt | compound_stmt\n"
"simple_stmt: small_stmt (';' small_stmt)* [';'] NEWLINE\n"
"small_stmt: (expr_stmt | del_stmt | pass_stmt | flow_stmt |\n"
"             import_stmt | global_stmt | nonlocal_stmt | assert_stmt)\n"
"expr_stmt: testlist_star_expr (annassign | augassign "
"(yield_expr|testlist) |\n"
"                     ('=' (yield_expr|testlist_star_expr))*)\n"
"annassign: ':' test ['=' test]\n"
"testlist_star_expr: (test|star_expr) (',' (test|star_expr))* [',']\n"
"augassign: ('+=' | '-=' | '*=' | '@=' | '/=' | '%=' | '&=' | '|=' | '^=' "
"|\n"
"            '<<=' | '>>=' | '**=' | '//=')\n"
"# For normal and annotated assignments, additional restrictions enforced "
"by the interpreter\n"
"del_stmt: 'del' exprlist\n"
"pass_stmt: 'pass'\n"
"flow_stmt: break_stmt | continue_stmt | return_stmt | raise_stmt | "
"yield_stmt\n"
"break_stmt: 'break'\n"
"continue_stmt: 'continue'\n"
"return_stmt: 'return' [testlist]\n"
"yield_stmt: yield_expr\n"
"raise_stmt: 'raise' [test ['from' test]]\n"
"import_stmt: import_name | import_from\n"
"import_name: 'import' dotted_as_names\n"
"# note below: the ('.' | '...') is necessary because '...' is tokenized "
"as ELLIPSIS\n"
"import_from: ('from' (('.' | '...')* dotted_name | ('.' | '...')+)\n"
"              'import' ('*' | '(' import_as_names ')' | import_as_names))"
"\n"
"import_as_name: NAME ['as' NAME]\n"
"dotted_as_name: dotted_name ['as' NAME]\n"
"import_as_names: import_as_name (',' import_as_name)* [',']\n"
"dotted_as_names: dotted_as_name (',' dotted_as_name)*\n"
"dotted_name: NAME ('.' NAME)*\n"
"global_stmt: 'global' NAME (',' NAME)*\n"
"nonlocal_stmt: 'nonlocal' NAME (',' NAME)*\n"
"assert_stmt: 'assert' test [',' test]\n"
"\n"
"compound_stmt: if_stmt | while_stmt | for_stmt | try_stmt | with_stmt | "
"funcdef | classdef | decorated | async_stmt\n"
"async_stmt: ASYNC (funcdef | with_stmt | for_stmt)\n"
"if_stmt: 'if' test ':' suite ('elif' test ':' suite)* ['else' ':' suite]\n"
"while_stmt: 'while' test ':' suite ['else' ':' suite]\n"
"for_stmt: 'for' exprlist 'in' testlist ':' suite ['else' ':' suite]\n"
"try_stmt: ('try' ':' suite\n"
"           ((except_clause ':' suite)+\n"
"            ['else' ':' suite]\n"
"            ['finally' ':' suite] |\n"
"           'finally' ':' suite))\n"
"with_stmt: 'with' with_item (',' with_item)*  ':' suite\n"
"with_item: test ['as' expr]\n"
"# NB compile.c makes sure that the default except clause is last\n"
"except_clause: 'except' [test ['as' NAME]]\n"
"suite: simple_stmt | NEWLINE INDENT stmt+ DEDENT\n"
"\n"
"test: or_test ['if' or_test 'else' test] | lambdef\n"
"test_nocond: or_test | lambdef_nocond\n"
"lambdef: 'lambda' [varargslist] ':' test\n"
"lambdef_nocond: 'lambda' [varargslist] ':' test_nocond\n"
"or_test: and_test ('or' and_test)*\n"
"and_test: not_test ('and' not_test)*\n"
"not_test: 'not' not_test | comparison\n"
"comparison: expr (comp_op expr)*\n"
"# <> isn't actually a valid comparison operator in Python. It's here for "
"the\n"
"# sake of a __future__ import described in PEP 401 (which really works "
":-)\n"
"comp_op: '<'|'>'|'=='|'>='|'<='|'<>'|'!='|'in'|'not' 'in'|'is'|'is' 'not'"
"\n"
"star_expr: '*' expr\n"
"expr: xor_expr ('|' xor_expr)*\n"
"xor_expr: and_expr ('^' and_expr)*\n"
"and_expr: shift_expr ('&' shift_expr)*\n"
"shift_expr: arith_expr (('<<'|'>>') arith_expr)*\n"
"arith_expr: term (('+'|'-') term)*\n"
"term: factor (('*'|'@'|'/'|'%'|'//') factor)*\n"
"factor: ('+'|'-'|'~') factor | power\n"
"power: atom_expr ['**' factor]\n"
"atom_expr: [AWAIT] atom trailer*\n"
"atom: ('(' [yield_expr|testlist_comp] ')' |\n"
"       '[' [testlist_comp] ']' |\n"
"       '{' [dictorsetmaker] '}' |\n"
"       NAME | NUMBER | STRING+ | '...' | 'None' | 'True' | 'False')\n"
"testlist_comp: (test|star_expr) ( comp_for | (',' (test|star_expr))* "
"[','] )\n"
"trailer: '(' [arglist] ')' | '[' subscriptlist ']' | '.' NAME\n"
"subscriptlist: subscript (',' subscript)* [',']\n"
"subscript: test | [test] ':' [test] [sliceop]\n"
"sliceop: ':' [test]\n"
"exprlist: (expr|star_expr) (',' (expr|star_expr))* [',']\n"
"testlist: test (',' test)* [',']\n"
"dictorsetmaker: ( ((test ':' test | '**' expr)\n"
"                   (comp_for | (',' (test ':' test | '**' expr))* [',']))"
" |\n"
"                  ((test | star_expr)\n"
"                   (comp_for | (',' (test | star_expr))* [','])) )\n"
"\n"
"classdef: 'class' NAME ['(' [arglist] ')'] ':' suite\n"
"\n"
"arglist: argument (',' argument)*  [',']\n"
"\n"
"# The reason that keywords are test nodes instead of NAME is that using "
"NAME\n"
"# results in an ambiguity. ast.c makes sure it's a NAME.\n"
"# \"test '=' test\" is really \"keyword '=' test\", but we have no such "
"token.\n"
"# These need to be in a single rule to avoid grammar that is ambiguous\n"
"# to our LL(1) parser. Even though 'test' includes '*expr' in star_expr,\n"
"# we explicitly match '*' here, too, to give it proper precedence.\n"
"# Illegal combinations and orderings are blocked in ast.c:\n"
"# multiple (test comp_for) arguments are blocked; keyword unpackings\n"
"# that precede iterable unpackings are blocked; etc.\n"
"argument: ( test [comp_for] |\n"
"            test '=' test |\n"
"            '**' test |\n"
"            '*' test )\n"
"\n"
"comp_iter: comp_for | comp_if\n"
"comp_for: [ASYNC] 'for' exprlist 'in' or_test [comp_iter]\n"
"comp_if: 'if' test_nocond [comp_iter]\n"
"\n"
"# not used in grammar, but may appear in \"node\" passed from Parser to "
"Compiler\n"
"encoding_decl: NAME\n"
"\n"
"yield_expr: 'yield' [yield_arg]\n"
"yield_arg: 'from' test | testlist\n"
msgstr ""

